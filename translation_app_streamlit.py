"""
ì˜ë¬¸ ê¸°ì‚¬ ë²ˆì—­ í”„ë¡œê·¸ë¨ (Streamlit UI)
Fine-tuned ëª¨ë¸ì„ ì‚¬ìš©í•œ ì˜ì–´â†’í•œêµ­ì–´ ë²ˆì—­
"""

# !pip install streamlit transformers torch

import streamlit as st
import torch
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
import re
import time
import pandas as pd
from datetime import datetime

# =====================================
# í˜ì´ì§€ ì„¤ì •
# =====================================

st.set_page_config(
    page_title="ì˜ë¬¸ ê¸°ì‚¬ ë²ˆì—­ê¸°",
    page_icon="ğŸ“°",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# CSS ìŠ¤íƒ€ì¼
st.markdown("""
    <style>
    .main {
        padding-top: 2rem;
    }
    .stTextArea textarea {
        font-size: 14px;
        font-family: 'Malgun Gothic', sans-serif;
    }
    .translation-box {
        background-color: #f0f2f6;
        padding: 20px;
        border-radius: 10px;
        margin: 10px 0;
    }
    h1 {
        color: #1f2937;
        border-bottom: 3px solid #4B79A1;
        padding-bottom: 10px;
    }
    .stats-box {
        background-color: #e8f4f8;
        padding: 15px;
        border-radius: 8px;
        border-left: 4px solid #4B79A1;
    }
    </style>
""", unsafe_allow_html=True)

# =====================================
# 1. ë²ˆì—­ ëª¨ë¸ í´ë˜ìŠ¤
# =====================================

@st.cache_resource
def load_model(model_path="./final-translation-model"):
    """
    ëª¨ë¸ì„ ë¡œë“œí•˜ê³  ìºì‹± (í•œ ë²ˆë§Œ ë¡œë“œ)
    """
    class TranslationModel:
        def __init__(self, model_path):
            self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
            
            try:
                # íŒŒì¸íŠœë‹ëœ ëª¨ë¸ ë¡œë“œ
                self.tokenizer = AutoTokenizer.from_pretrained(model_path)
                self.model = AutoModelForSeq2SeqLM.from_pretrained(model_path)
                st.success(f"âœ… Fine-tuned ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            except:
                # ì›ë³¸ ëª¨ë¸ ë¡œë“œ
                model_name = "Helsinki-NLP/opus-mt-tc-big-en-ko"
                self.tokenizer = AutoTokenizer.from_pretrained(model_name)
                self.model = AutoModelForSeq2SeqLM.from_pretrained(model_name)
                st.info(f"â„¹ï¸ ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©: {model_name}")
            
            self.model = self.model.to(self.device)
            self.model.eval()
        
        def split_into_sentences(self, text):
            """ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• """
            sentences = re.split(r'(?<=[.!?])\s+', text)
            return [s.strip() for s in sentences if s.strip()]
        
        def translate_sentence(self, sentence, max_length=256):
            """ë‹¨ì¼ ë¬¸ì¥ ë²ˆì—­"""
            inputs = self.tokenizer(
                sentence,
                return_tensors="pt",
                max_length=max_length,
                truncation=True,
                padding=True
            ).to(self.device)
            
            with torch.no_grad():
                outputs = self.model.generate(
                    **inputs,
                    max_length=max_length,
                    num_beams=5,
                    temperature=0.9,
                    do_sample=False,
                    early_stopping=True
                )
            
            return self.tokenizer.decode(outputs[0], skip_special_tokens=True)
        
        def translate_article(self, article_text, progress_callback=None):
            """ì „ì²´ ê¸°ì‚¬ ë²ˆì—­"""
            if not article_text.strip():
                return ""
            
            paragraphs = article_text.split('\n')
            translated_paragraphs = []
            total_sentences = sum(len(self.split_into_sentences(p)) for p in paragraphs if p.strip())
            current_sentence = 0
            
            for paragraph in paragraphs:
                if not paragraph.strip():
                    translated_paragraphs.append("")
                    continue
                
                sentences = self.split_into_sentences(paragraph)
                translated_sentences = []
                
                for sentence in sentences:
                    if sentence:
                        translation = self.translate_sentence(sentence)
                        translated_sentences.append(translation)
                        current_sentence += 1
                        
                        # ì§„í–‰ë¥  ì½œë°±
                        if progress_callback:
                            progress_callback(current_sentence / total_sentences)
                
                translated_paragraph = ' '.join(translated_sentences)
                translated_paragraphs.append(translated_paragraph)
            
            return '\n'.join(translated_paragraphs)
    
    return TranslationModel(model_path)

# =====================================
# 2. ë©”ì¸ UI
# =====================================

# ì œëª©
st.markdown("<h1>ğŸ“° ì˜ë¬¸ ê¸°ì‚¬ ë²ˆì—­ê¸°</h1>", unsafe_allow_html=True)
st.markdown("**Fine-tuned ëª¨ë¸ì„ ì‚¬ìš©í•œ ì˜ì–´â†’í•œêµ­ì–´ ê¸°ì‚¬ ë²ˆì—­**")

# ëª¨ë¸ ë¡œë“œ
if 'translator' not in st.session_state:
    with st.spinner('ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ” ì¤‘...'):
        st.session_state.translator = load_model()

# ë²ˆì—­ íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
if 'history' not in st.session_state:
    st.session_state.history = []

# ì‚¬ì´ë“œë°” - ì„¤ì • ë° íˆìŠ¤í† ë¦¬
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    
    # ë²ˆì—­ ì˜µì…˜
    preserve_paragraphs = st.checkbox("ë‹¨ë½ êµ¬ì¡° ìœ ì§€", value=True)
    show_stats = st.checkbox("í†µê³„ ì •ë³´ í‘œì‹œ", value=True)
    
    st.divider()
    
    # ë²ˆì—­ íˆìŠ¤í† ë¦¬
    st.header("ğŸ“‹ ë²ˆì—­ íˆìŠ¤í† ë¦¬")
    if st.session_state.history:
        for i, item in enumerate(reversed(st.session_state.history[-5:])):
            with st.expander(f"{item['time']} - {item['preview']}..."):
                st.text("ì›ë¬¸:")
                st.write(item['original'][:200] + "...")
                st.text("ë²ˆì—­:")
                st.write(item['translated'][:200] + "...")
    else:
        st.info("ì•„ì§ ë²ˆì—­ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤")
    
    if st.button("ê¸°ë¡ ì‚­ì œ"):
        st.session_state.history = []
        st.rerun()

# ë©”ì¸ ì»¨í…ì¸  - 2ì—´ ë ˆì´ì•„ì›ƒ
col1, col2 = st.columns(2)

with col1:
    st.subheader("ì˜ë¬¸ ê¸°ì‚¬")
    
    # í…ìŠ¤íŠ¸ ì…ë ¥
    english_text = st.text_area(
        "",
        height=400,
        placeholder="ë²ˆì—­í•  ì˜ë¬¸ ê¸°ì‚¬ë¥¼ ì…ë ¥í•˜ì„¸ìš”...\n\nEnter English article text here...",
        key="english_input"
    )
    
    # ì˜ˆì œ í…ìŠ¤íŠ¸
    st.markdown("**ğŸ“ ì˜ˆì œ ê¸°ì‚¬**")
    col_ex1, col_ex2, col_ex3 = st.columns(3)
    
    example_texts = {
        "AI ë‰´ìŠ¤": """Breaking News: AI Technology Advances

Artificial intelligence continues to revolutionize various industries. Machine learning models are becoming more sophisticated and accessible to developers worldwide.

Recent developments in natural language processing have led to significant improvements in translation accuracy.""",
        
        "ê¸°í›„ ë³€í™”": """Climate Change Report

Scientists have released a new report on climate change impacts. The study shows that global temperatures are rising faster than previously predicted.

Immediate action is needed to reduce carbon emissions.""",
        
        "ê¸°ìˆ  í˜ì‹ ": """Technology Innovation

A new breakthrough in quantum computing has been announced. Researchers claim this could revolutionize data processing speeds.

The technology shows promising results for future applications."""
    }
    
    with col_ex1:
        if st.button("AI ë‰´ìŠ¤"):
            st.session_state.english_input = example_texts["AI ë‰´ìŠ¤"]
            st.rerun()
    
    with col_ex2:
        if st.button("ê¸°í›„ ë³€í™”"):
            st.session_state.english_input = example_texts["ê¸°í›„ ë³€í™”"]
            st.rerun()
    
    with col_ex3:
        if st.button("ê¸°ìˆ  í˜ì‹ "):
            st.session_state.english_input = example_texts["ê¸°ìˆ  í˜ì‹ "]
            st.rerun()

with col2:
    st.subheader("ë²ˆì—­ëœ í•œê¸€ ê¸°ì‚¬")
    
    # ë²ˆì—­ ê²°ê³¼ í‘œì‹œ ì˜ì—­
    translation_container = st.empty()
    stats_container = st.empty()
    
    # ì´ˆê¸° í”Œë ˆì´ìŠ¤í™€ë”
    translation_container.text_area(
        "",
        value="",
        height=400,
        placeholder="ë²ˆì—­ ê²°ê³¼ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤...",
        key="korean_output",
        disabled=True
    )

# ë²ˆì—­ ë²„íŠ¼
col_btn1, col_btn2, col_btn3 = st.columns([2, 1, 1])

with col_btn1:
    if st.button("ğŸ”„ ë²ˆì—­í•˜ê¸°", type="primary", use_container_width=True):
        if english_text:
            # ì§„í–‰ í‘œì‹œ
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            def update_progress(progress):
                progress_bar.progress(progress)
                status_text.text(f"ë²ˆì—­ ì¤‘... {int(progress * 100)}%")
            
            # ë²ˆì—­ ì‹œì‘
            start_time = time.time()
            status_text.text("ë²ˆì—­ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
            
            try:
                # ë²ˆì—­ ì‹¤í–‰
                translated_text = st.session_state.translator.translate_article(
                    english_text,
                    progress_callback=update_progress
                )
                
                # ë²ˆì—­ ì‹œê°„
                translation_time = time.time() - start_time
                
                # ê²°ê³¼ í‘œì‹œ
                with col2:
                    # ë²ˆì—­ ê²°ê³¼
                    st.text_area(
                        "",
                        value=translated_text,
                        height=400,
                        key="korean_output_result",
                        disabled=True
                    )
                    
                    # í†µê³„ ì •ë³´
                    if show_stats:
                        word_count = len(english_text.split())
                        char_count = len(english_text)
                        
                        stats_html = f"""
                        <div class="stats-box">
                            <h4>ğŸ“Š ë²ˆì—­ í†µê³„</h4>
                            <ul>
                                <li>ì›ë¬¸ ë‹¨ì–´ ìˆ˜: {word_count}ê°œ</li>
                                <li>ì›ë¬¸ ë¬¸ì ìˆ˜: {char_count}ì</li>
                                <li>ë²ˆì—­ ì‹œê°„: {translation_time:.2f}ì´ˆ</li>
                                <li>í‰ê·  ì†ë„: {word_count/translation_time:.1f} ë‹¨ì–´/ì´ˆ</li>
                            </ul>
                        </div>
                        """
                        st.markdown(stats_html, unsafe_allow_html=True)
                
                # íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
                st.session_state.history.append({
                    'time': datetime.now().strftime("%H:%M:%S"),
                    'preview': english_text[:30],
                    'original': english_text,
                    'translated': translated_text
                })
                
                # ì§„í–‰ í‘œì‹œ ì œê±°
                progress_bar.empty()
                status_text.success("âœ… ë²ˆì—­ ì™„ë£Œ!")
                
            except Exception as e:
                st.error(f"âŒ ë²ˆì—­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                progress_bar.empty()
                status_text.empty()
        else:
            st.warning("âš ï¸ ë²ˆì—­í•  í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”")

with col_btn2:
    if st.button("ğŸ—‘ï¸ ì§€ìš°ê¸°", use_container_width=True):
        st.session_state.english_input = ""
        st.session_state.korean_output = ""
        st.rerun()

with col_btn3:
    # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ (ë²ˆì—­ ê²°ê³¼ê°€ ìˆì„ ë•Œë§Œ)
    if 'korean_output_result' in st.session_state and st.session_state.korean_output_result:
        st.download_button(
            label="ğŸ’¾ ì €ì¥",
            data=st.session_state.korean_output_result,
            file_name=f"translation_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
            mime="text/plain",
            use_container_width=True
        )

# í•˜ë‹¨ ì •ë³´
st.divider()
st.markdown("""
<div style='background-color: #f8f9fa; padding: 20px; border-radius: 10px;'>
    <h4>ğŸ’¡ ì‚¬ìš© íŒ</h4>
    <ul>
        <li>ê¸´ ê¸°ì‚¬ë„ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ì–´ ì •í™•í•˜ê²Œ ë²ˆì—­í•©ë‹ˆë‹¤</li>
        <li>ë‹¨ë½ êµ¬ì¡°ê°€ ìë™ìœ¼ë¡œ ìœ ì§€ë˜ì–´ ê°€ë…ì„±ì´ ì¢‹ìŠµë‹ˆë‹¤</li>
        <li>GPU ì‚¬ìš© ì‹œ ë” ë¹ ë¥¸ ë²ˆì—­ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤</li>
    </ul>
    <h4>âš ï¸ ì£¼ì˜ì‚¬í•­</h4>
    <ul>
        <li>ì „ë¬¸ ìš©ì–´ë‚˜ ê³ ìœ ëª…ì‚¬ëŠ” ì™„ë²½í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤</li>
        <li>ë§¤ìš° ê¸´ ë¬¸ì¥ì€ ì—¬ëŸ¬ ë¬¸ì¥ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ë²ˆì—­í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤</li>
    </ul>
</div>
""", unsafe_allow_html=True)

# =====================================
# 3. ì‹¤í–‰ ë°©ë²•
# =====================================

# í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰:
# streamlit run translation_app_streamlit.py
